# QUICK START GUIDE - Toxic Phrase Detection Model

## ğŸš€ Báº¯t Äáº§u Nhanh (5 phÃºt)

### BÆ°á»›c 1: CÃ i Ä‘áº·t
```bash
pip install pandas
```

### BÆ°á»›c 2: Sá»­ dá»¥ng cÆ¡ báº£n
```python
from model import ToxicPhraseDetector

# Khá»Ÿi táº¡o model
detector = ToxicPhraseDetector('slang.csv')

# PhÃ¢n tÃ­ch má»™t cÃ¢u
result = detector.detect("This ragebait is pure brainrot")

# Xem káº¿t quáº£
print(f"Toxic: {result['is_toxic']}")          # True
print(f"Count: {result['toxic_count']}")       # 2
print(f"Phrases: {result['toxic_phrases']}")   # ['ragebait', 'brainrot']
```

### BÆ°á»›c 3: Cháº¡y thá»­
```bash
# Test vá»›i CLI
python model.py --text "Your sentence here"

# Xem demo
python demo_toxic_model.py

# Cháº¡y evaluation
python evaluate_toxic_model.py

# Cháº¡y tests
python test_toxic_model.py
```

## ğŸ“Š Káº¿t Quáº£

âœ… **Accuracy: 100%**  
âœ… **17/17 Tests Passed**  
âœ… **892 Toxic Phrases Loaded**  
âœ… **Sáºµn sÃ ng sá»­ dá»¥ng**

## ğŸ“– Chi Tiáº¿t

Xem `README_TOXIC_MODEL.md` vÃ  `TOXIC_MODEL_SUMMARY.md` Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t.

## ğŸ’¡ VÃ­ Dá»¥ Nhanh

```python
# PhÃ¢n tÃ­ch nhiá»u cÃ¢u
sentences = [
    "Great day!",
    "Stop the ragebait",
    "This is brainrot content"
]

results = detector.batch_detect(sentences)
for sentence, result in zip(sentences, results):
    print(f"{sentence}: {result['toxic_count']} toxic phrases")
```

## ğŸ¯ TÃ­nh NÄƒng ChÃ­nh

- âœ… Nháº­n diá»‡n tá»«/cá»¥m tá»« toxic
- âœ… Äáº¿m sá»‘ lÆ°á»£ng toxic phrases
- âœ… Case-insensitive
- âœ… Batch processing
- âœ… CLI support
- âœ… 100% accuracy

**That's it! Báº¯t Ä‘áº§u sá»­ dá»¥ng ngay! ğŸ‰**
